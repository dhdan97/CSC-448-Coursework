{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhdan97/CSC-448-Coursework/blob/main/a4_Daniel_H_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8PKiVJaL_AW"
      },
      "outputs": [],
      "source": [
        "# Imports and pip installations (if needed)\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhdan97/CSC-448-Coursework/blob/main/a4_Daniel_H_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "iftLKmuXo4Ww"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A05Q5B0_NUX9"
      },
      "source": [
        "# Part 1: Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ4MUsbXNZ0P",
        "outputId": "899083ae-9cf0-404d-f34e-7f801b14b606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                 5.1               3.5                1.4               0.2\n",
            "1                 4.9               3.0                1.4               0.2\n",
            "2                 4.7               3.2                1.3               0.2\n",
            "3                 4.6               3.1                1.5               0.2\n",
            "4                 5.0               3.6                1.4               0.2\n",
            "5                 5.4               3.9                1.7               0.4\n",
            "6                 4.6               3.4                1.4               0.3\n",
            "7                 5.0               3.4                1.5               0.2\n",
            "8                 4.4               2.9                1.4               0.2\n",
            "9                 4.9               3.1                1.5               0.1\n",
            "10                5.4               3.7                1.5               0.2\n",
            "11                4.8               3.4                1.6               0.2\n",
            "12                4.8               3.0                1.4               0.1\n",
            "13                4.3               3.0                1.1               0.1\n",
            "14                5.8               4.0                1.2               0.2\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   sepal length (cm)  150 non-null    float64\n",
            " 1   sepal width (cm)   150 non-null    float64\n",
            " 2   petal length (cm)  150 non-null    float64\n",
            " 3   petal width (cm)   150 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 4.8 KB\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset (load remotely, not locally)\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
        "# Output the first 15 rows of the data\n",
        "print(df.head(15))\n",
        "# Display a summary of the table information (number of datapoints, etc.)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRMtsJKBaxWu"
      },
      "source": [
        "## About the dataset\n",
        "Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data contains sepal and petal length and width measurements of 150 flowers, categorized into 3 types of the iris plant. The sepal and petal length and width are our features and the type of iris plant are our labels. We are mapping the 3 different strings to one of the 3 types of iris plant."
      ],
      "metadata": {
        "id": "Ji4JFgPZZb_O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhKaIrZKNaHg"
      },
      "source": [
        "# Part 2: Split the dataset into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrgogB62NcOi"
      },
      "outputs": [],
      "source": [
        "# Take the dataset and split it into our features (X) and label (y)\n",
        "X = df[[\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\"]]\n",
        "y = iris.target\n",
        "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hblF-ei9Ncia"
      },
      "source": [
        "# Part 3: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhFhEN03Nf7o",
        "outputId": "afd88819-43d7-4f8b-f514-722900689b62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With sepal length 5.1cm, sepal width 3.5cm, petal length 1.4cm, and petal width 0.2cm, our model predicts that this is a setosa\n",
            "Given our test features and labels, our score is: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "\n",
        "# i. Use sklearn to train a LogisticRegression model on the training set\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X, y)\n",
        "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
        "sample = [[5.1, 3.5, 1.4, 0.2]]\n",
        "with warnings.catch_warnings(record=True): samplePrediction = iris.target_names[logreg.predict(sample)[0]]\n",
        "print(\"With sepal length 5.1cm, sepal width 3.5cm, petal length 1.4cm, and petal width 0.2cm, our model predicts that this is a \" + samplePrediction)\n",
        "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
        "print(\"Given our test features and labels, our score is: \" + str(\"{:#.5g}\".format(logreg.score(X_test,y_test))))\n",
        "# iv. Extract the coefficents and intercepts for the boundary line(s)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logreg.coef_"
      ],
      "metadata": {
        "id": "KUdBCt6ugo7j",
        "outputId": "a612994e-4c9c-438f-8bc9-10c6bdc5f8b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.41878528,  0.96703041, -2.5209973 , -1.08417682],\n",
              "       [ 0.53124457, -0.31475282, -0.20008433, -0.94861142],\n",
              "       [-0.1124593 , -0.65227759,  2.72108162,  2.03278825]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logreg.intercept_"
      ],
      "metadata": {
        "id": "1OQCKyhZgr4c",
        "outputId": "c214f930-533c-496f-f62b-f8b7729c59d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  9.84037025,   2.21700109, -12.05737134])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With sepal length 5.1cm, sepal width 3.5cm, petal length 1.4cm, and petal width 0.2cm, our model predicts that this is a Setosa.\n",
        "\n",
        "The score for our Logisitc regression model measures the mean accuracy on the given test data and labels. We have a score of 1, meaning every test datapoint was correctly classified with our model."
      ],
      "metadata": {
        "id": "chpWdXR0gudF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDUpXQN4Nilk"
      },
      "source": [
        "# Part 4: Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U__zukpdNqiQ",
        "outputId": "f5f00622-a50d-4737-9314-c8979b5bd8be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With sepal length 5.1cm, sepal width 3.5cm, petal length 1.4cm, and petal width 0.2cm, our model predicts that this is a setosa\n",
            "Given our test features and labels, our score is: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
        "svm = SVC().fit(X_train, y_train)\n",
        "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
        "sample = [[5.1, 3.5, 1.4, 0.2]]\n",
        "with warnings.catch_warnings(record=True): samplePrediction = iris.target_names[svm.predict(sample)[0]]\n",
        "print(\"With sepal length 5.1cm, sepal width 3.5cm, petal length 1.4cm, and petal width 0.2cm, our model predicts that this is a \" + samplePrediction)\n",
        "# iii. Report on the score for the SVM, what does the score measure?\n",
        "print(\"Given our test features and labels, our score is: \" + str(\"{:#.5g}\".format(svm.score(X_test,y_test))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our score for a Support Vector Machine also measures the mean accuracy on the given test data and labels, and it correctly predicted every test entry with a score of 1.0"
      ],
      "metadata": {
        "id": "Y2Vxns8gmYth"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULoL7mMBNrlS"
      },
      "source": [
        "# Part 5: Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKKmODVrN9lQ",
        "outputId": "0f6f94d9-f32b-46b5-b235-b7c70f484786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With sepal length 5.1cm, sepal width 3.5cm, petal length 1.4cm, and petal width 0.2cm, our model predicts that this is a setosa\n",
            "Given our test features and labels, our score is: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
        "MLP = MLPClassifier().fit(X_train, y_train)\n",
        "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
        "sample = [[5.1, 3.5, 1.4, 0.2]]\n",
        "with warnings.catch_warnings(record=True): samplePrediction = iris.target_names[MLP.predict(sample)[0]]\n",
        "print(\"With sepal length 5.1cm, sepal width 3.5cm, petal length 1.4cm, and petal width 0.2cm, our model predicts that this is a \" + samplePrediction)\n",
        "# iii. Report on the score for the Neural Network, what does the score measure?\n",
        "print(\"Given our test features and labels, our score is: \" + str(\"{:#.5g}\".format(MLP.score(X_test,y_test))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)\n",
        "MLP_logistic = MLPClassifier(activation='logistic').fit(X_train, y_train)\n",
        "print(\"Given our test features and labels, our score is: \" + str(\"{:#.5g}\".format(MLP_logistic.score(X_test,y_test))))"
      ],
      "metadata": {
        "id": "0TwDP7DZ1s78",
        "outputId": "698558c1-0da9-46b5-e19c-ee2ea9823c01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given our test features and labels, our score is: 0.86667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_lbfgs = MLPClassifier(solver='lbfgs').fit(X_train, y_train)\n",
        "print(\"Given our test features and labels, our score is: \" + str(\"{:#.5g}\".format(MLP_lbfgs.score(X_test,y_test))))"
      ],
      "metadata": {
        "id": "Ubm70u-C3bKN",
        "outputId": "16ee32b6-3c00-4880-8896-4006c4d4a984",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given our test features and labels, our score is: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our best configuration is the one with the default activation function 'relu' and solver 'adam' with 200 iterations, getting a score of 1.0"
      ],
      "metadata": {
        "id": "EDaY7WyX3_9O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bi5tDwHmC28"
      },
      "source": [
        "# Part 6: K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCFlfJy2mCg6",
        "outputId": "60f65a2d-33bf-4efb-80fe-11a726c0a524",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.8 0.2 0. ]]\n",
            "Given our features, our score is: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ],
      "source": [
        "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
        "# Note: KNN is a nonparametric model and technically doesn't require training\n",
        "# fit will essentially load the data into the model see link below for more information\n",
        "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
        "neigh = KNeighborsClassifier().fit(X_train, y_train)\n",
        "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
        "sample = [[2.1, 0.5, 0.2, 5.1]]\n",
        "print(neigh.predict_proba(sample))\n",
        "# iii. Report on the score for kNN, what does the score measure?\n",
        "print(\"Given our features, our score is: \" + str(\"{:#.5g}\".format(neigh.score(X_test,y_test))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "162Sw3LeoqE2"
      },
      "source": [
        "# Part 7: Conclusions and takeaways\n",
        "\n",
        "In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of my model were surprising, most of them getting a perfect score of 1.0. I believe this is happening because we are doing the maximum number of iterations (which might be too many iterations i.e. overfitting). Any future work would be on finding the number of iterations that still provides a good score in order to decrease complexity and overfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "lufZOHQnxOhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hBSXTieL5Hkv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "a4_Daniel_H_notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}