{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhdan97/CSC-448-Coursework/blob/main/a4_Daniel_H_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S8PKiVJaL_AW"
      },
      "outputs": [],
      "source": [
        "# Imports and pip installations (if needed)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A05Q5B0_NUX9"
      },
      "source": [
        "# Part 1: Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ4MUsbXNZ0P",
        "outputId": "8e906b29-5e35-402f-fec4-db062f7e54c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    sepal.length  sepal.width  petal.length  petal.width variety\n",
            "0            5.1          3.5           1.4          0.2  Setosa\n",
            "1            4.9          3.0           1.4          0.2  Setosa\n",
            "2            4.7          3.2           1.3          0.2  Setosa\n",
            "3            4.6          3.1           1.5          0.2  Setosa\n",
            "4            5.0          3.6           1.4          0.2  Setosa\n",
            "5            5.4          3.9           1.7          0.4  Setosa\n",
            "6            4.6          3.4           1.4          0.3  Setosa\n",
            "7            5.0          3.4           1.5          0.2  Setosa\n",
            "8            4.4          2.9           1.4          0.2  Setosa\n",
            "9            4.9          3.1           1.5          0.1  Setosa\n",
            "10           5.4          3.7           1.5          0.2  Setosa\n",
            "11           4.8          3.4           1.6          0.2  Setosa\n",
            "12           4.8          3.0           1.4          0.1  Setosa\n",
            "13           4.3          3.0           1.1          0.1  Setosa\n",
            "14           5.8          4.0           1.2          0.2  Setosa\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal.length  150 non-null    float64\n",
            " 1   sepal.width   150 non-null    float64\n",
            " 2   petal.length  150 non-null    float64\n",
            " 3   petal.width   150 non-null    float64\n",
            " 4   variety       150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset (load remotely, not locally)\n",
        "df = pd.read_csv(\"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\");\n",
        "\n",
        "# Output the first 15 rows of the data\n",
        "print(df.head(15))\n",
        "# Display a summary of the table information (number of datapoints, etc.)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRMtsJKBaxWu"
      },
      "source": [
        "## About the dataset\n",
        "Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data contains sepal and petal length and width measurements of 150 flowers, categorized into 3 types of the iris plant. The sepal and petal length and width are our features and the type of iris plant are our labels. We are mapping the 3 different strings to one of the 3 types of iris plant."
      ],
      "metadata": {
        "id": "Ji4JFgPZZb_O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhKaIrZKNaHg"
      },
      "source": [
        "# Part 2: Split the dataset into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrgogB62NcOi"
      },
      "outputs": [],
      "source": [
        "# Take the dataset and split it into our features (X) and label (y)\n",
        "\n",
        "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hblF-ei9Ncia"
      },
      "source": [
        "# Part 3: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhFhEN03Nf7o"
      },
      "outputs": [],
      "source": [
        "# i. Use sklearn to train a LogisticRegression model on the training set\n",
        "\n",
        "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
        "\n",
        "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
        "\n",
        "# iv. Extract the coefficents and intercepts for the boundary line(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDUpXQN4Nilk"
      },
      "source": [
        "# Part 4: Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U__zukpdNqiQ"
      },
      "outputs": [],
      "source": [
        "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
        "\n",
        "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
        "\n",
        "# iii. Report on the score for the SVM, what does the score measure?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULoL7mMBNrlS"
      },
      "source": [
        "# Part 5: Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKKmODVrN9lQ"
      },
      "outputs": [],
      "source": [
        "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
        "\n",
        "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
        "\n",
        "# iii. Report on the score for the Neural Network, what does the score measure?\n",
        "\n",
        "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bi5tDwHmC28"
      },
      "source": [
        "# Part 6: K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCFlfJy2mCg6"
      },
      "outputs": [],
      "source": [
        "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
        "# Note: KNN is a nonparametric model and technically doesn't require training\n",
        "# fit will essentially load the data into the model see link below for more information\n",
        "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
        "\n",
        "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
        "\n",
        "# iii. Report on the score for kNN, what does the score measure?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "162Sw3LeoqE2"
      },
      "source": [
        "# Part 7: Conclusions and takeaways\n",
        "\n",
        "In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "a4_Daniel_H_notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}