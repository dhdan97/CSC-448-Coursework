{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhdan97/CSC-488-Coursework/blob/main/a3_Daniel_H_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxt0KLthb_M6"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhdan97/CSC-488-Coursework/blob/main/a3_Daniel_H_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\\(\\^Be sure to update this button to point to your notebook instead of the sample notebook\\)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ifXoXwMpb_M9"
      },
      "outputs": [],
      "source": [
        "# Imports section\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7sm7wJXb_M-"
      },
      "source": [
        "## Part 1. Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IJEcuCQpb_M_",
        "outputId": "544c7746-060e-4666-cb16-95b8fe89e6b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Temperature °C  Mols KCL     Size nm^3\n",
            "0              469       647  6.244743e+05\n",
            "1              403       694  5.779610e+05\n",
            "2              302       975  6.196847e+05\n",
            "3              779       916  1.460449e+06\n",
            "4              901        18  4.325726e+04\n",
            "5              545       637  7.124634e+05\n",
            "6              660       519  7.006960e+05\n",
            "7              143       869  2.718260e+05\n",
            "8               89       461  8.919803e+04\n",
            "9              294       776  4.770210e+05\n",
            "10             991       117  2.441771e+05\n",
            "11             307       781  5.006455e+05\n",
            "12             206        70  3.145200e+04\n",
            "13             437       599  5.390215e+05\n",
            "14             566        75  9.185271e+04\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Temperature °C  1000 non-null   int64  \n",
            " 1   Mols KCL        1000 non-null   int64  \n",
            " 2   Size nm^3       1000 non-null   float64\n",
            "dtypes: float64(1), int64(2)\n",
            "memory usage: 23.6 KB\n"
          ]
        }
      ],
      "source": [
        "# Using pandas load the dataset (load remotely, not locally)\n",
        "Slime = pd.read_csv(\"https://raw.githubusercontent.com/profmcnich/example_notebook/main/science_data_large.csv\")\n",
        "# Output the first 15 rows of the data\n",
        "print(Slime.head(15))\n",
        "# Display a summary of the table information (number of datapoints, etc.)\n",
        "Slime.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-03VcBXb_M_"
      },
      "source": [
        "## Part 2. Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kPLsRTFRb_M_"
      },
      "outputs": [],
      "source": [
        "# Take the pandas dataset and split it into our features (X) and label (y)\n",
        "X = Slime[['Temperature °C', 'Mols KCL']]\n",
        "y = Slime['Size nm^3']\n",
        "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryGeaMv8b_NA"
      },
      "source": [
        "## Part 3. Perform a Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RKWsRbEmb_NA",
        "outputId": "2e106fd3-7764-4145-9448-d3a5cb2615cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With Temperature of 469°C and 647 Mols of KCL, our model predicts a size of 6.6498e+05 nm^3\n",
            "Given our test features and labels, our score is: 0.85525\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "\n",
        "# Use sklearn to train a model on the training set\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "# Create a sample datapoint and predict the output of that sample with the trained model\n",
        "sample = [[469, 647]]\n",
        "with warnings.catch_warnings(record=True): samplePrediction = str(\"{:#.5g}\".format((reg.predict(sample)[0])))\n",
        "print(\"With Temperature of 469°C and 647 Mols of KCL, our model predicts a size of \" + samplePrediction + \" nm^3\")\n",
        "# Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
        "print(\"Given our test features and labels, our score is: \" + str(\"{:#.5g}\".format(reg.score(X_test,y_test))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Our score is defined as (1 - u/v), where u is the residual sum of squares and v is the total sum of squares.\n",
        "\n",
        "###This means our score is a ratio of how close our predicted answers are to the observed answers(labels) over how much our label values vary.\n",
        "\n",
        "###The smaller our residual sum of squares and/or the greater our label variance, the better our score.\n",
        "\n",
        "###I would consider a score of 0.85525 very good for our first result"
      ],
      "metadata": {
        "id": "XWPlhJhu1IBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
        "reg.coef_"
      ],
      "metadata": {
        "id": "Z322BKbOvwQe",
        "outputId": "e0e21c22-04ef-4862-c278-d49ddf77867a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 866.14641337, 1032.69506649])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg.intercept_"
      ],
      "metadata": {
        "id": "XabNA3Ki6Cho",
        "outputId": "4fa97395-f7d6-4a40-c322-720df83a8562",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-409391.47958340764"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSRAuCL1b_NB"
      },
      "source": [
        "Sample equation: $E = mc^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$h(x) = 866.14x + 1032.6x - 4.0939 * 10^{5}$"
      ],
      "metadata": {
        "id": "20_5aSiI6LWX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH54SDdgb_NB"
      },
      "source": [
        "## Part 4. Use Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T9pqIW4Cb_NC",
        "outputId": "4d06ca45-845a-491d-e1a1-643353f597bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.83918826, 0.87051239, 0.85871066, 0.87202623, 0.84364641])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Use the cross_val_score function to repeat your experiment across many shuffles of the data\n",
        "scores = cross_val_score(reg, X, y)\n",
        "# Report on their finding and their significance\n",
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###With 5-fold cross validation, it looks like our 4th entry produced the greatest score. This means that the combination of spliting our data into 5 parts, and using the 4th part as our testing data gave us a greater score than any other combination of 5 parts here."
      ],
      "metadata": {
        "id": "lC-INjHpAmIg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qa9kaXYb_NC"
      },
      "source": [
        "## Part 5. Using Polynomial Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XKBaOLRFb_NC"
      },
      "outputs": [],
      "source": [
        "# Using the PolynomialFeatures library perform another regression on an augmented dataset of degree 2\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "polyX = poly.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(polyX, y, test_size=0.10, random_state=42)\n",
        "\n",
        "reg = LinearRegression().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Report on the metrics and output the resultant equation as you did in Part 3.\n",
        "print(\"Given our test features and labels, our score is: \" + str(\"{:#.5g}\".format(reg.score(X_test,y_test))))"
      ],
      "metadata": {
        "id": "Z3WpbOkzDe4W",
        "outputId": "7d0b4730-8dc9-4e6c-fb73-b7dc17b42c48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given our test features and labels, our score is: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###A score of 1.0 means our model is perfect, i.e our residual sum of squares is 0."
      ],
      "metadata": {
        "id": "gpMWRNDYEYFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_"
      ],
      "metadata": {
        "id": "2EF_MV-_D5Sq",
        "outputId": "df1f6498-c23f-48bf-b8fa-a460122751e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00000000e+00,  1.20000000e+01, -1.27195488e-07,  1.26494371e-11,\n",
              "        2.00000000e+00,  2.85714287e-02])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg.intercept_"
      ],
      "metadata": {
        "id": "CIgZvs_4Dxmb",
        "outputId": "290de5ff-54dd-4729-8993-efc6b368b6f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0477105863392353e-05"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$h(x) = 12x_{1} + (-1.2718*10^{7})x_{2} + (1.2649*10^{-11})x_{1}x_{2} + 2x_{1}^{2} + (2.8571*10^{-2})x_{2}^{2}$"
      ],
      "metadata": {
        "id": "_pSlNPkbD_oG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gjYxLXxAGGg4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "a3_Daniel_H_notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}